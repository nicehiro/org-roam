:PROPERTIES:
:ID:       E16E8A92-C645-4DE0-A936-5B6A48276F38
:END:
#+title: Skew-Fit: State-Covering Self-Supervised Reinforcement Learning
#+filetags: :sequential:


Try to find subgoals by maximizing the [[id:C7B2A00C-FEC1-47D2-8FE5-301A8E147D58][mutual information]]:

$$
I(S;G) = H(S) - H(S|G) = H(G) - H(G|S)
$$

that is trying to maximizing $H(S)$ and minimizing $H(S|G)$.

To minimizing $H(S|G)$, we train a policy by maximizing the reward:
$$
r = log(G|S)
$$
which is also the distance between $G$ and $S$. This paper use [[id:64612DC9-6058-4E57-96CE-97705C040C5E][RIG]] to deal with it.

To maximizing $H(S)$, they add a weight on each state to make the probability of less visited state become bigger.


