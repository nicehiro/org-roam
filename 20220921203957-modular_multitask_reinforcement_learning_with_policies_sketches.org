:PROPERTIES:
:ID:       D47D697C-B9A4-4A75-B18E-733C8420E293
:END:
#+title: Modular Multitask Reinforcement Learning with Policy Sketches
#+filetags: :curriculum-learning:rl:multi-task:


Give the policy sketches, which means the order (or the graph) of subtasks is known as prior. Thus, this paper is mainly focus on the 'low' level of this hierarchical problem, but from a global perspective.


The idea is simple:
1. train policy $\pi_i$ for each subtask $i$, thus the policy of whole task is $\pi = [\pi_i]$

2. collect data and curriculum learning methods to learn each sub policy


The most novel idea of this paper is that they use a novel MDP, more specifically, a _novel state transition probability to describe the relationship_ in multi-task MDP.


