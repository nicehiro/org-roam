#+title: Backpropagate Gradient
#+filed: Optimization
#+OPTIONS: toc:nil
#+roam_alias: math
#+roam_tags:

* Description
之前学习了如何训练好的环境动力学模型，以及基于模型的强化学习的基本训练方法，
这节主要讲如何使用模型来训练策略。
当然可以用我们最熟悉的梯度下降法。
#+BEGIN_CENTER
#+ATTR_ORG: :width 600
#+ATTR_HTML: :width 100%
[[file:./img/rl-sergey/lec-12-1.png]]
#+END_CENTER
这种方法有什么缺点呢？
#+BEGIN_CENTER
#+ATTR_ORG: :width 600
#+ATTR_HTML: :width 100%
[[file:./img/rl-sergey/lec-12-2.png]]
#+END_CENTER
上图是基于模型的方法的反向传播示意图。其中，由于模型是训练到的函数，所以模型函数也会参与到梯度的传播过程中，
就会导致一系列的梯度相乘叠加。
由于梯度在传播过程中叠加性，越靠 Trajectory 结尾，其梯度越小，越靠 Trajectory 开头，梯度越大。
所以很容易发生梯度爆炸的问题。其次就是之前提到的全局策略的缺点，牵一发而动全身，误差会不断累积增大。
