<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2021-07-13 Tue 09:38 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>Survey of Zero Shot Learning</title>
<meta name="generator" content="Org mode" />
<meta name="author" content="Fangyuan" />
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<script type="text/javascript">
// @license magnet:?xt=urn:btih:e95b018ef3580986a04669f1b5879592219e2a7a&dn=public-domain.txt Public Domain
<!--/*--><![CDATA[/*><!--*/
     function CodeHighlightOn(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.add("code-highlighted");
         target.classList.add("code-highlighted");
       }
     }
     function CodeHighlightOff(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.remove("code-highlighted");
         target.classList.remove("code-highlighted");
       }
     }
    /*]]>*///-->
// @license-end
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<h1 class="title">Survey of Zero Shot Learning</h1>

<div id="outline-container-orgb4557db" class="outline-2">
<h2 id="orgb4557db"><span class="section-number-2">1</span> Views</h2>
<div class="outline-text-2" id="text-1">
<p>
The aim of zero-shot learning is to classify instances belonging to the class that have
no labeled instances. In zero-shot learning, the classes covered by the training instances
are referred to as the seen classes, and the classes not covered by the training instances
which are unlabeled testing instances are referred to as the unseen classes.
</p>

<p>
Zero-shot learning is a special kind of transfer learning. Based on whether the feature
spaces and label spaces in the source and target domains/tasks are the same, transfer
learning can be classified into <i>homogeneous transfer learning</i> and <i>heterogeneous transfer learning</i>.
In zero-shot learning, the source feature space is the feature space of training instances,
and the target feature space is the feature space of testing instances. They are the same.
However, the source label space is the seen class, while the target label space is the
unseen class. They are different. So, zero-shot learning belongs to <b>heterogeneous transfer learning</b>.
</p>
</div>


<div id="outline-container-orgff8bce0" class="outline-3">
<h3 id="orgff8bce0"><span class="section-number-3">1.1</span> Learning Settings</h3>
<div class="outline-text-3" id="text-1-1">
<table border="2" cellspacing="0" cellpadding="6" rules="groups" frame="hsides">


<colgroup>
<col  class="org-left" />

<col  class="org-left" />

<col  class="org-left" />
</colgroup>
<thead>
<tr>
<th scope="col" class="org-left">Learning Settings</th>
<th scope="col" class="org-left">Involved in Model Learning</th>
<th scope="col" class="org-left">Characteristic</th>
</tr>
</thead>
<tbody>
<tr>
<td class="org-left">CIII</td>
<td class="org-left">\(D^{tr}, T^{s}\)</td>
<td class="org-left">severe domain shift, but more general</td>
</tr>

<tr>
<td class="org-left">CTII</td>
<td class="org-left">\(D^{tr}, T^{s}, T^{u}\)</td>
<td class="org-left">soft domain shift</td>
</tr>

<tr>
<td class="org-left">CTIT</td>
<td class="org-left">\(D^{tr}, T^{s}, T^{u}, X^{te}\)</td>
<td class="org-left">soft domain shift, but lower general</td>
</tr>
</tbody>
</table>

<ol class="org-ol">
<li>\(D^{tr}\) is the labeled training instances, \(T^{s}\) is the seen class prototypes,
\(X^{te}\) is the unlabeled testing instances, \(T^{u}\) is the unseen class prototypes.</li>
<li>In machine learning methods, as the distributions of the training and the testing
instances are different, the performance of the model learned with the training
instances will decrease when applied to the testing instances. This phenomenon is more
severe in zero-shot learning, and it is usually referred to as <i>domain shift</i>.</li>
<li>Under CIII setting, as the model are not optimized for specific unseen classes and
testing instances, when new unseen classes or testing instances need to be classified,
the generalization ability of models learned is usually better than model learned
under other settings.</li>
</ol>
</div>
</div>
</div>

<div id="outline-container-org9835a45" class="outline-2">
<h2 id="org9835a45"><span class="section-number-2">2</span> Semantic Spaces</h2>
<div class="outline-text-2" id="text-2">
<p>
Semantic spaces contain semantic information about <i>classes</i> and are important part of
zero-shot learning. According to how a semantic space is constructed, we categorize them
as engineered semantic spaces and learned semantic spaces.
</p>

<!-- This HTML table template is generated by emacs 27.2 -->
<table border="1">
  <tr>
    <td align="left" valign="top">
      &nbsp;Semantic&nbsp;Spaces&nbsp;Type&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    </td>
    <td align="left" valign="top">
      &nbsp;Advantages&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    </td>
    <td align="left" valign="top">
      &nbsp;Disadvantages&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    </td>
  </tr>
  <tr>
    <td align="left" valign="top">
      &nbsp;Engineered&nbsp;Semantic&nbsp;Spaces&nbsp;
    </td>
    <td align="left" valign="top">
      &nbsp;easy&nbsp;to&nbsp;encode&nbsp;human&nbsp;domain&nbsp;knowledge&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    </td>
    <td align="left" valign="top">
      &nbsp;heavily&nbsp;rely&nbsp;on&nbsp;humans&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
    </td>
  </tr>
  <tr>
    <td align="left" valign="top">
      &nbsp;Learned&nbsp;Semantic&nbsp;Spaces&nbsp;&nbsp;&nbsp;&nbsp;
    </td>
    <td align="left" valign="top">
      &nbsp;less&nbsp;labor&nbsp;intensive,&nbsp;contain&nbsp;more&nbsp;information&nbsp;
    </td>
    <td align="left" valign="top">
      &nbsp;model's&nbsp;unpredictable&nbsp;and&nbsp;hard&nbsp;to&nbsp;understand&nbsp;
    </td>
  </tr>
</table>
</div>

<div id="outline-container-orgc018fca" class="outline-3">
<h3 id="orgc018fca"><span class="section-number-3">2.1</span> Engineered Semantic Spaces</h3>
<div class="outline-text-3" id="text-2-1">
<p>
In engineered semantic spaces, each dimension of the semantic space is designed by humans.
</p>
</div>

<div id="outline-container-org35fa93c" class="outline-4">
<h4 id="org35fa93c"><span class="section-number-4">2.1.1</span> Attribute Spaces</h4>
<div class="outline-text-4" id="text-2-1-1">
<p>
Attribute spaces are kinds of semantic spaces that are constructed by a set of
attributes of the classes. For example, in the problem of animal recognition in images,
there are three attributes: "having stripes", "living on land" and "plant eating".
For the class "tiger", it's semantic space is \([1, 1, 0]\), and for the class "horse",
it's semantic space is \([0, 1, 1]\). The above attribute space is binary attribute space,
there are also other attribute spaces, like continuous attribute spaces.
</p>
</div>
</div>

<div id="outline-container-org36184ae" class="outline-4">
<h4 id="org36184ae"><span class="section-number-4">2.1.2</span> Lexical Spaces</h4>
<div class="outline-text-4" id="text-2-1-2">
<p>
Lexical spaces are based on the <i>labels</i> of the classes and datasets that can provide
semantic information. The dataset can be some structured lexical databases, such as
WordNet. You can use the hierarchical relationships in WordNet to construct the
semantic space by setting the prototype of label \(i\) with label \(j\) \(t_{ij}\) to 1 if
label i and j have a relationship else to 0.
</p>
</div>
</div>

<div id="outline-container-org9e1b15a" class="outline-4">
<h4 id="org9e1b15a"><span class="section-number-4">2.1.3</span> Text-keyword Spaces</h4>
<div class="outline-text-4" id="text-2-1-3">
<p>
Text-keyword spaces are kinds of semantic spaces that are constructed by a set of
keywords extracted from the text descriptions of each class. The most common source of
the text descriptions is websites such as Wikipedia.
</p>
</div>
</div>
</div>

<div id="outline-container-org67d396d" class="outline-3">
<h3 id="org67d396d"><span class="section-number-3">2.2</span> Learned Semantic Spaces</h3>
<div class="outline-text-3" id="text-2-2">
<p>
In learned semantic spaces, the prototypes of each class are obtained from the output of
some machine-learning models. So each dimension does not have an explicit semantic
meaning.
</p>
</div>

<div id="outline-container-org51afb55" class="outline-4">
<h4 id="org51afb55"><span class="section-number-4">2.2.1</span> Label-embedding Spaces</h4>
<div class="outline-text-4" id="text-2-2-1">
<p>
This kind of space is introduced in view of the development and wide utilization of
word embedding techniques in natural language processing. It's prototypes are obtained
through the embedding of class labels.
</p>
</div>
</div>

<div id="outline-container-org8ee81ba" class="outline-4">
<h4 id="org8ee81ba"><span class="section-number-4">2.2.2</span> Text-embedding Spaces</h4>
<div class="outline-text-4" id="text-2-2-2">
<p>
The prototypes of text-embedding spaces are obtained by embedding the text descriptions
for each class.
</p>
</div>
</div>

<div id="outline-container-org939c529" class="outline-4">
<h4 id="org939c529"><span class="section-number-4">2.2.3</span> Image-embedding Spaces</h4>
<div class="outline-text-4" id="text-2-2-3">
<p>
The prototype of image-embedding spaces are obtained from images belonging to each class.
</p>
</div>
</div>
</div>
</div>


<div id="outline-container-orga0839c4" class="outline-2">
<h2 id="orga0839c4"><span class="section-number-2">3</span> Methods</h2>
<div class="outline-text-2" id="text-3">
</div>
<div id="outline-container-orgf4aa0a0" class="outline-3">
<h3 id="orgf4aa0a0"><span class="section-number-3">3.1</span> Classifier-Based Methods</h3>
<div class="outline-text-3" id="text-3-1">
<p>
Existing classifier-based methods usually take a one-versus-rest solution for learning the
multiclass zero-shot classifier. Therefor, the eventual zero-shot classifier \(f^{u}(\cdot)\)
for the unseen classes consists of \(N_u\) binary one-versus-rest classifiers
\(f_{i}^{u}|i=1,\cdots,N_u\).
</p>
</div>

<div id="outline-container-org7fd1857" class="outline-4">
<h4 id="org7fd1857"><span class="section-number-4">3.1.1</span> Correspondence Methods</h4>
<div class="outline-text-4" id="text-3-1-1">
<p>
It's insight is to construct the classifier for unseen class via the correspondence between
the binary one-versus-rest classifier for each class and its corresponding class prototype.
</p>

<p>
For each class, there is just one corresponding prototype and one corresponding binary
one-versus-rest classifier. Correspondence methods aim to learn a correspondence function
between these two.
</p>

<p>
First, with the available data, the correspondence function \(\phi(\cdot;\theta)\) is learned,
which take the prototype \(t_i\) of the class \(c_i\) as input and outputs the parameter \(w_i\)
of the binary one-versus-rest classifier \(f_{i}(\cdot;w_i)\).
Then, for each unseen class \(c_{i}^{u}\), with its prototype \(t^{u}_{i}\) and the learned
correspondence function \(\phi(\cdot;\theta)\), the classifier can be constructed.
</p>

<p>
学习一个从 class 到 classifier 的映射。
</p>
</div>
</div>

<div id="outline-container-org7217a52" class="outline-4">
<h4 id="org7217a52"><span class="section-number-4">3.1.2</span> Relationship Methods</h4>
<div class="outline-text-4" id="text-3-1-2">
<p>
It's insight is to construct the classifier for unseen class via the relationships among
the seen and the unseen class as well as the binary one-versus-rest classifier of the
seen class.
</p>

<p>
First, with the available data, the binary one-versus-rest classifier of the seen classes
can be learned.
Then, the relationships among the seen and the unseen classes are calculated via the
corresponding class prototypes or obtained through other approaches.
</p>

<p>
学习 unseen lable 和 seen lable 之间的关系，学习 seen label 的 classifier。
</p>
</div>
</div>

<div id="outline-container-org07dd91a" class="outline-4">
<h4 id="org07dd91a"><span class="section-number-4">3.1.3</span> Combination Methods</h4>
<div class="outline-text-4" id="text-3-1-3">
<p>
Its insight is to construct the classifier for unseen class via the combination of classifiers
for basic elements that are used to constitute the classes.
</p>

<p>
First, with the available data, the attribute binary one-versus-rest classifiers can be
learned. Than the classifier for the unseen classes can be constructed.
</p>

<p>
For example,
\[
f^{u}(\cdot) = Fmk(f_{1}^{a}(\cdot),\cdots,f_{M}^{a}(\cdot))
\]
</p>

<p>
学习属性的分类器。
</p>
</div>
</div>
</div>

<div id="outline-container-orgb573790" class="outline-3">
<h3 id="orgb573790"><span class="section-number-3">3.2</span> Instance-Based Methods</h3>
<div class="outline-text-3" id="text-3-2">
<p>
These methods aim to first obtain labeled instances for the unseen classes, then with these
instances to learn the zero-shot classifier.
</p>
</div>

<div id="outline-container-orgf006f84" class="outline-4">
<h4 id="orgf006f84"><span class="section-number-4">3.2.1</span> Projection Methods</h4>
<div class="outline-text-4" id="text-3-2-1">
<p>
Its insight is to obtain labeled instances for the unseen classes by projecting both the
feature space instances and the semantic space prototypes into a common space.
</p>

<p>
First, instances \(x_i\) in the feature space \(\chi\) and the prototypes \(t_j\) in the
semantic space \(\mathcal{T}\) are projected into the projection space \(\mathcal{P}\).
As for each unseen class, it does not have labeled instance in the feature space, so it's
difficult to learn classifier like SVM or logistic regression classifiers with so few labeled
instances.
As a result, in existing projection methods, the classification is usually performed by
nearest neighbor classification or some variants of it.
</p>
</div>
</div>

<div id="outline-container-orgf0cf5ca" class="outline-4">
<h4 id="orgf0cf5ca"><span class="section-number-4">3.2.2</span> Instance-Borrowing Methods</h4>
<div class="outline-text-4" id="text-3-2-2">
<p>
Its insight is to obtain labeled instances for the unseen classes by borrowing from the
training instances.
</p>
</div>
</div>

<div id="outline-container-org3fad7ac" class="outline-4">
<h4 id="org3fad7ac"><span class="section-number-4">3.2.3</span> Synthesizing Methods</h4>
<div class="outline-text-4" id="text-3-2-3">
<p>
Its insight is to obtain labeled instances for the unseen classes by synthesizing some
pseudo instances.
</p>
</div>
</div>
</div>
</div>

<div id="outline-container-org5d85bd1" class="outline-2">
<h2 id="org5d85bd1"><span class="section-number-2">4</span> Reference</h2>
<div class="outline-text-2" id="text-4">
<p>
<a href="wangSurveyZeroShotLearning2019">Survery of Zero Shot Learning</a>
</p>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: Fangyuan</p>
<p class="date">Created: 2021-07-13 Tue 09:38</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
