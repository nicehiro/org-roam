:PROPERTIES:
:ID:       8AA412D7-D9A6-4471-B8EA-251FF8D576AD
:ROAM_REFS: @yueDeeRVLADynamicInference2024
:END:
#+title: DeeR-VLA: Dynamic Inference of Multimodal Large Language Models for Efficient Robot Execution
#+filetags: :VLA:


This paper tries to address the challenge that current VLAs high computation and memory capacities. They introduce Dynamic Early-Exit for Robotic VLA models that automatically adjusts the size of the activated MLLM based on each situation at hand, allowing the model to terminate processing once a proper size of the model has been activated for a specific situation, thus avoiding further redundant computation.

During training, they randomly sample features from max-pooling-ed all hidden states of MLLM. During inference, they activate an appropriate size of MLLM based on an exit criterion, which accounts for the current situation and predefined computational and GPU memory budgets.
